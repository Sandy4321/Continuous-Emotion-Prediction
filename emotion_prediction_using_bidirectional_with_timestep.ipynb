{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here emotion prediction was done by using Bi directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "\n",
    "from sys     import argv\n",
    "#from sklearn import svm\n",
    "\n",
    "from load_features     import load_all\n",
    "#from calc_scores       import calc_scores\n",
    "#from write_predictions import write_predictions\n",
    "\n",
    "# Set folders here\n",
    "path_test_predictions = \"D:/AVEC_17_Emotion_Sub-Challenge/result/\"\n",
    "b_test_available      = False  # If the test labels are not available, the predictions on test are written into the folder 'path_test_predictions'\n",
    "\n",
    "# Folders wi o_features = \"E:/AVEC_17_Emotion_Sub-Challenge/audio_features_xbow_6s/\"\n",
    "path_audio_features = \"D:/AVEC_17_Emotion_Sub-Challenge/audio_features_xbow_6s/\"\n",
    "path_video_features = \"D:/AVEC_17_Emotion_Sub-Challenge/video_features_xbow_6s/\"\n",
    "path_text_features  = \"D:/AVEC_17_Emotion_Sub-Challenge/text_features_xbow_6s/\"\n",
    "path_labels         = \"D:/AVEC_17_Emotion_Sub-Challenge/labels/\"\n",
    "\n",
    "sr_labels = 0.1\n",
    "\n",
    "delay = 0.00\n",
    "b_audio = True\n",
    "b_video = True\n",
    "b_text  = True\n",
    "rise = 0.20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_features = []\n",
    "if b_audio:\n",
    "    path_features.append( path_audio_features )\n",
    "if b_video:\n",
    "    path_features.append( path_video_features )\n",
    "if b_text:\n",
    "    path_features.append( path_text_features )\n",
    "        \n",
    "\n",
    "if not b_test_available and not os.path.exists(path_test_predictions):\n",
    "    os.mkdir(path_test_predictions)\n",
    "\n",
    "# Compensate the delay (quick solution)\n",
    "shift = int(np.round(delay/sr_labels))\n",
    "shift = np.ones(len(path_features),dtype=int)*shift\n",
    "\n",
    "\n",
    "\n",
    "files_train = fnmatch.filter(os.listdir(path_features[0]), \"Train*\")  # Filenames are the same for audio, video, text & labels\n",
    "files_devel = fnmatch.filter(os.listdir(path_features[0]), \"Devel*\")\n",
    "files_test  = fnmatch.filter(os.listdir(path_features[0]), \"Test*\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Load features and labels\n",
    "Train   = load_all( files_train, path_features, shift )\n",
    "Devel   = load_all( files_devel, path_features, shift )\n",
    "Train_L = load_all( files_train, [ path_labels ] )  # Labels are not shifted\n",
    "Devel_L = load_all( files_devel, [ path_labels ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making windowing for train data.Like input sequence will be[t1,t2,t3],[t2,t3,t4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def create_data(dataset,look_back=1):\n",
    "        dataX = []\n",
    "        for i in range(len(dataset)-look_back+1):\n",
    "            a = dataset[i:i+look_back,:]\n",
    "            dataX.append(a)\n",
    "        return np.array(dataX)\n",
    "\n",
    "    def create_dataY(dataset,look_back=1):\n",
    "        dataX = []\n",
    "        for i in range(len(dataset)-look_back+1):\n",
    "            a = dataset[i:i+look_back,]\n",
    "            dataX.append(a)\n",
    "        return np.array(dataX)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "    Train_LA = Train_L[:,0]\n",
    "    TrainX = Train\n",
    "    TrainY = Train_LA\n",
    "\n",
    "    look_back = 6\n",
    "    \n",
    "    New_TrainX = create_data(TrainX,look_back)\n",
    "    New_TrainY = create_dataY(TrainY,look_back)\n",
    "#TrainY[1:3,]\n",
    "\n",
    "    Devel_X = create_data(Devel,look_back)\n",
    "    Devel_Y = create_dataY(Devel_L[:,0],look_back)\n",
    "    \n",
    "    \n",
    "    Y = New_TrainY.reshape(len(TrainX)-look_back+1,look_back,1)\n",
    "    X = New_TrainX.reshape(len(TrainX)-look_back+1,look_back,4521)\n",
    "#Devel_X.shape\n",
    "    Devel_Y = Devel_Y.reshape(len(Devel)-look_back+1,look_back,1)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    np.random.seed(5)\n",
    "    CCC_max = list()\n",
    "    PCC_max = list()\n",
    "    for a in range(12):\n",
    "        import tensorflow as tf\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import LSTM\n",
    "        from keras.layers import Dense\n",
    "        from keras.layers import TimeDistributed\n",
    "        from keras.layers import Bidirectional\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(200,return_sequences = True),input_shape=(look_back,4521)))\n",
    "        model.add(Bidirectional(LSTM(200,return_sequences = True),input_shape=(look_back,4521)))\n",
    "        model.add(Bidirectional(LSTM(100,return_sequences = True),input_shape=(look_back,4521)))\n",
    "        model.add(Bidirectional(LSTM(100,return_sequences = True),input_shape=(look_back,4521)))\n",
    "\n",
    "        model.add(TimeDistributed(Dense(1, activation= 'linear' )))\n",
    "        model.compile(loss = 'mean_squared_error',optimizer = 'adam',metrics = ['accuracy'],options = run_opts)\n",
    "        print(model.summary())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        #Devel_X = Devel.reshape(22727,1,4521)\n",
    "        #Devel_Y = Devel_L[:,0].reshape(22727,1,1)\n",
    "\n",
    "        model.fit(X,Y,epochs = 1,validation_data=(Devel_X, Devel_Y))\n",
    "        pred = model.predict(Devel_X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating CCC,PCC,RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "        a = []\n",
    "        for i in range(len(pred)):\n",
    "            a.append(pred[i,0])\n",
    "        for j in range(1,look_back):\n",
    "            a.append(pred[i,j])\n",
    "        a = np.array(a)\n",
    "\n",
    "        a = a.reshape(22727,)\n",
    "    \n",
    "    \n",
    "        #pred = pred.reshape(22727,)\n",
    "\n",
    "        x = a\n",
    "        y = Devel_L[:,0]\n",
    "#y = Y\n",
    "        x_mean = np.nanmean(x)\n",
    "        y_mean = np.nanmean(y)\n",
    "\n",
    "#np.nanmean((x - x_mean) * (y - y_mean)) \n",
    "        covariance = np.nanmean((x-x_mean)*(y-y_mean))\n",
    "    \n",
    "        x_var = 1.0 / (len(x)-1) * np.nansum((x-x_mean)**2) # Make it consistent with Matlab's nanvar (division by len(x)-1, not len(x)))\n",
    "        y_var = 1.0 / (len(y)-1) * np.nansum((y-y_mean)**2)\n",
    "    \n",
    "        CCC = (2*covariance) / (x_var + y_var + (x_mean-y_mean)**2)\n",
    "\n",
    "        x_std = np.sqrt(x_var)\n",
    "        y_std = np.sqrt(y_var)\n",
    "        PCC = covariance / (x_std * y_std)\n",
    "    \n",
    "        RMSE = np.sqrt(np.nanmean((x - y)**2))\n",
    "    \n",
    "        CCC_max.append(CCC)\n",
    "        PCC_max.append(PCC)\n",
    "        model.reset_states()\n",
    "        print(CCC_max)\n",
    "    CCC_W = max(CCC_max)\n",
    "    PCC_W = max(PCC_max)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside run_baseline.py\n",
      "3\n",
      "argv\n",
      "['c:\\\\users\\\\abhijit\\\\anaconda3\\\\envs\\\\tensorflow-gpu\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\abhijit\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-a3b15971-281f-4f10-96f3-a4db35a275aa.json']\n",
      "delay\n",
      "0.0\n",
      "i am going\n",
      "['Train_01.csv', 'Train_02.csv', 'Train_03.csv', 'Train_04.csv', 'Train_05.csv', 'Train_06.csv', 'Train_07.csv', 'Train_08.csv', 'Train_09.csv', 'Train_10.csv', 'Train_11.csv', 'Train_12.csv', 'Train_13.csv', 'Train_14.csv', 'Train_15.csv', 'Train_16.csv', 'Train_17.csv', 'Train_18.csv', 'Train_19.csv', 'Train_20.csv', 'Train_21.csv', 'Train_22.csv', 'Train_23.csv', 'Train_24.csv', 'Train_25.csv', 'Train_26.csv', 'Train_27.csv', 'Train_28.csv', 'Train_29.csv', 'Train_30.csv', 'Train_31.csv', 'Train_32.csv', 'Train_33.csv', 'Train_34.csv']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_5 (Bidirection (None, 6, 400)            7555200   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 6, 400)            961600    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 6, 200)            400800    \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 6, 200)            240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 6, 1)              201       \n",
      "=================================================================\n",
      "Total params: 9,158,601\n",
      "Trainable params: 9,158,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 56087 samples, validate on 22722 samples\n",
      "Epoch 1/1\n",
      "56087/56087 [==============================] - 274s 5ms/step - loss: 0.0019 - acc: 0.0234 - val_loss: 0.0161 - val_acc: 0.0215\n",
      "[0.3738645380375504]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_9 (Bidirection (None, 6, 400)            7555200   \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 6, 400)            961600    \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 6, 200)            400800    \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 6, 200)            240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 6, 1)              201       \n",
      "=================================================================\n",
      "Total params: 9,158,601\n",
      "Trainable params: 9,158,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 56087 samples, validate on 22722 samples\n",
      "Epoch 1/1\n",
      "56087/56087 [==============================] - 260s 5ms/step - loss: 0.0019 - acc: 0.0234 - val_loss: 0.0164 - val_acc: 0.0215\n",
      "[0.3738645380375504, 0.3750830698753424]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_13 (Bidirectio (None, 6, 400)            7555200   \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 6, 400)            961600    \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 6, 200)            400800    \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 6, 200)            240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 6, 1)              201       \n",
      "=================================================================\n",
      "Total params: 9,158,601\n",
      "Trainable params: 9,158,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 56087 samples, validate on 22722 samples\n",
      "Epoch 1/1\n",
      "  864/56087 [..............................] - ETA: 7:59 - loss: 0.0122 - acc: 0.0264"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-21ea71a953ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m#Devel_Y = Devel_L[:,0].reshape(22727,1,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDevel_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDevel_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDevel_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijit\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    with open(\"results_ccc_timestep_6.txt\", 'a') as myfile:\n",
    "    #myfile.write(\" Arousal Valence Liking\\n\")\n",
    "        myfile.write(str(CCC_W) + '\\n')\n",
    "    with open(\"results_pcc_timestep_6.txt\", 'a') as myfile:\n",
    "    #myfile.write(\"Arousal Valence Liking\\n\")\n",
    "        myfile.write(str(PCC_W) + '\\n')\n",
    "    model.reset_states()\n",
    "    delay = delay + rise\n",
    "    print(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
